{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Surveying Neural Spiking in Visual Cortex with Pandas and Seaborn\n",
        "\n",
        "Ole Bialas  \n",
        "2025-09-03\n",
        "\n",
        "Modern electrophysiology equipment like the [Neuropixels\n",
        "probes](https://en.wikipedia.org/wiki/Neuropixels) allows for\n",
        "simultaneous recording of hundreds of neurons. This leaves researchers\n",
        "with massive amounts of data to process and visualize. Fortunately, the\n",
        "Python ecosystem provides powerful tools for generating beautiful\n",
        "visualizations from large amounts of data in only a few lines of code.\n",
        "In this post, I’ll use data from a [2021 study by Joshua Siegle and\n",
        "colleagues](https://www.nature.com/articles/s41586-020-03171-x)[1],\n",
        "conducted at the Allen Institute, where they recorded tens of thousands\n",
        "of neurons from six different cortical regions across multiple\n",
        "experimental conditions.\n",
        "\n",
        "In this post, I’ll take the recordings from a single animal that was\n",
        "presented with bright flashes. I’ll visualize the responses across\n",
        "cortical regions in peri-stimulus time histograms (PSTHs) using Pandas\n",
        "and Seaborn. Why Pandas and Seaborn? While these libraries are not\n",
        "geared towards electrophysiological data, they offer established\n",
        "powerful tools for analyzing large amounts of data. A good understanding\n",
        "of Pandas and Seaborn will also be useful in a variety of scenarios\n",
        "since these libraries are widely used in academia and industry.\n",
        "\n",
        "To follow along with my examples, install the required packages and\n",
        "download the data as described in the next section.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "First we have to install the required modules using `pip`:\n",
        "\n",
        "    pip install numpy matplotlib seaborn pandas pyarrow\n",
        "\n",
        "Then, we can import the installed modules and download the data. We need\n",
        "two data frames — one containing the timing of the presented stimuli and\n",
        "another one containing the recorded spikes. Conveniently, all `read_`\n",
        "functions in Pandas accept URLs and can gracefully handle the\n",
        "downloading for us.\n",
        "\n",
        "[1] Siegle, J. H., Jia, X., Durand, S., Gale, S., Bennett, C., Graddis,\n",
        "N., … & Koch, C. (2021). Survey of spiking in the mouse visual system\n",
        "reveals functional hierarchy. Nature, 592(7852), 86-92."
      ],
      "id": "62ef2e4a-a9a5-4940-82c8-3a801da902ea"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "df_stimuli = pd.read_parquet(\"https://uni-bonn.sciebo.de/s/G64EkHoQkeZeoLm/download\")\n",
        "df_spikes = pd.read_parquet(\"https://uni-bonn.sciebo.de/s/mLMkb2TwbNx3Yg6/download\")"
      ],
      "id": "5f2f29c3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Referencing Spike Times to Stimulus Presentations\n",
        "\n",
        "First, let’s take a look at the data. We have two data frames:\n",
        "`df_stimuli` contains the start and stop time for every stimulus [1] and\n",
        "`df_spikes` contains the unit ID, brain area and time for every recorded\n",
        "spike.\n",
        "\n",
        "[1] All stimuli are full-field flashes so there isn’t any relevant\n",
        "information besides the stimuli’s timing"
      ],
      "id": "859684e2-cc7e-4d16-aee2-af632780454d"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_stimuli.head(5)"
      ],
      "id": "27ef117e-ee57-4d79-b8a6-ccbe975dbfb9"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_spikes.head(5)"
      ],
      "id": "c912c501-f428-4b3c-a242-5160053bea90"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To be able to relate the spiking to the presented stimuli, we have to\n",
        "combine the information from\n",
        "<a href=\"#tbl-stim\" class=\"quarto-xref\">Table 1</a> and\n",
        "<a href=\"#tbl-spikes\" class=\"quarto-xref\">Table 2</a>. To do this, we\n",
        "first create a new column in the stimulus dataframe called\n",
        "`\"analysis_window_start\"`[1] which is simply the stimulus onset minus\n",
        "0.5 seconds. Then, we use `pd.merge_asof()` to match every spike with\n",
        "the closest analysis window. In the merged data frame `df`, we subtract\n",
        "the stimulus start time from the spike time which gives us the spike\n",
        "time relative to the stimulus. Finally, we remove all relative spike\n",
        "time values greater than 1 and remove the columns we don’t need. The\n",
        "final dataframe contains all spikes happening between 0.5 seconds before\n",
        "and 1.0 seconds after stimulus onset.\n",
        "\n",
        "[1] We could skip creating the `\"analysis_window_start\"` column and\n",
        "merge the data using the stimulus onsets. However, then we would lose\n",
        "the spikes that occur right before the onset which we need to compute\n",
        "the baseline."
      ],
      "id": "8b4acb09-9669-4ca6-a3eb-795eaf1f330d"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_stimuli[\"analysis_window_start\"] = df_stimuli.start_time - 0.5\n",
        "df = pd.merge_asof(\n",
        "    df_spikes, df_stimuli, left_on=\"spike_time\", right_on=\"analysis_window_start\"\n",
        ")\n",
        "df.spike_time -= df.start_time\n",
        "df = df[df.spike_time <= 1.0]\n",
        "df = df[[\"spike_time\", \"brain_area\", \"unit_id\"]]\n",
        "df.sample(5)"
      ],
      "id": "ce52b1b5-c219-435c-b38e-c3c0fd864fe4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a Peri-Stimulus Time Histogram\n",
        "\n",
        "Now we can quantify how the spiking changes in response to the stimulus.\n",
        "To do this, we create an array of 10 millisecond wide bins between -0.5\n",
        "and 1.0 seconds, group the data by unit ID and brain area and count the\n",
        "spike time values that fall into each bin. Finally, we reset the index\n",
        "of the returned series, take the middle of each bin and rename the\n",
        "columns. The resulting dataframe contains the spike count for every unit\n",
        "in every bin."
      ],
      "id": "1f92200d-1249-4743-9315-2c0dfb56ea4a"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "bins = np.arange(-0.5, 1, 0.01)\n",
        "psth = (\n",
        "    df.groupby([\"unit_id\", \"brain_area\"])\n",
        "    .spike_time.value_counts(bins=bins)\n",
        "    .reset_index()\n",
        ")\n",
        "psth.spike_time = psth.spike_time.array.mid\n",
        "psth.columns = [\"unit_id\", \"brain_area\", \"bin_time\", \"spike_count\"]\n",
        "psth.sample(5)"
      ],
      "id": "ca7fd177-211f-4d60-bd8f-51b9645a74e5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To visualize the PSTH, we’ll use seaborn’s `relplot()` function to plot\n",
        "the spike counts against the bin times. We can also add reference lines\n",
        "at 0 and 0.25 seconds that mark the stimulus onset and offset. There is\n",
        "a clear pattern — spiking increases after the onset, falls back to\n",
        "baseline, increases again after the offset, drops below the baseline and\n",
        "then rebounds."
      ],
      "id": "5b4e912d-3ec5-463f-a6f5-db68f42de293"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "g = sns.relplot(data=psth, x=\"bin_time\", y=\"spike_count\", kind=\"line\")\n",
        "g.refline(x=0, color=\"black\", linestyle=\"--\", alpha=0.5)\n",
        "g.refline(x=0.25, color=\"black\", linestyle=\"--\", alpha=0.5)"
      ],
      "id": "cell-fig-average_psth"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also add a `hue` to encode the brain area and zoom in on the\n",
        "x-axis in order to make out differences in the spiking profile between\n",
        "brain areas (we’ll set `errorbar=None` because the overlapping\n",
        "confidence intervals will make the plot hard to read)."
      ],
      "id": "1be10c33-d206-4f1f-885e-6cbd877f60fe"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "g = sns.relplot(data=psth, x=\"bin_time\", y=\"spike_count\", kind=\"line\" , hue=\"brain_area\", errorbar=None)\n",
        "g.set(xlim=(-0.1, 0.5))"
      ],
      "id": "cell-fig-area_psth"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that spiking in the primary visual cortex V1 peaks first\n",
        "which is expected since it represents the lowest level in the visual\n",
        "processing hierarchy. However, there are large differences in the\n",
        "average firing rate between areas which makes this plot hard to read. To\n",
        "overcome this limitation we have to apply baseline correction.\n",
        "\n",
        "## Applying a Baseline Correction\n",
        "\n",
        "To compute the baselines, we select all spikes that happen before 0\n",
        "seconds (i.e. the stimulus onset), group the data by unit ID and\n",
        "calculate the mean spike count to obtain an estimate of each unit’s\n",
        "average firing rate in absence of the stimulus. Then, we merge the\n",
        "baseline estimates with the PSTH and create a new column called\n",
        "`\"spike_count_change\"` by subtracting the baseline from the spike count."
      ],
      "id": "7c2d68eb-8b57-4417-9487-c9c55b5da4d1"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline = psth[psth.bin_time < 0].groupby([\"unit_id\"]).spike_count.mean()\n",
        "baseline.name = \"baseline\"\n",
        "psth = psth.merge(baseline, on=\"unit_id\")\n",
        "psth[\"spike_count_change\"] = psth.spike_count - psth.baseline\n",
        "psth.sample(5)"
      ],
      "id": "faa1d4bc-65f2-4743-a4a0-30d964213c81"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can recreate our area-specific PSTH plot using the spike count\n",
        "change — the result looks much clearer!"
      ],
      "id": "c651e92f-fcbb-49e5-a942-32d8deb03fc1"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "g = sns.relplot(\n",
        "    data=psth,\n",
        "    x=\"bin_time\",\n",
        "    y=\"spike_count_change\",\n",
        "    kind=\"line\",\n",
        "    hue=\"brain_area\",\n",
        "    errorbar=None,\n",
        ")\n",
        "g.set(xlim=(-0.1, 0.5))"
      ],
      "id": "cell-fig-baseline_psth"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, there is still a problem: the number of units that respond to\n",
        "the stimulus varies across brain areas as higher visual areas generally\n",
        "respond less to simple flashes which confounds our analysis. In order to\n",
        "interpret the absolute spike counts we need to identify the units that\n",
        "actually respond to the stimuli.\n",
        "\n",
        "## Identifying Responsive Units\n",
        "\n",
        "To identify the responsive units, we first compute the relative change\n",
        "in spiking by dividing the baseline subtracted spikecount by the\n",
        "baseline. We add a small regularization coefficient $\\epsilon$ to avoid\n",
        "that baseline values close to 0 inflate the estimate [1]. Then, we can\n",
        "plot the relative change in spiking for every unit (this requires\n",
        "setting `estimator=None`). Let’s add a horizontal line to mark the\n",
        "threshold for responsiveness — in this example, we want to consider a\n",
        "unit responsive if its relative spike count increases 5 times with\n",
        "respect to the baseline. This method of identifying responsive units is\n",
        "not statistically rigorous, but it is a quick and convenient way of\n",
        "filtering the data for visualization.\n",
        "\n",
        "[1] The exact value of $\\epsilon$ is not that relevant here, so feel\n",
        "free to try out different values. However, be aware that larger values\n",
        "of $\\epsilon$ will lead to smaller values of the relative change in\n",
        "spike count for all units, so you’ll have to adapt the threshold as\n",
        "well."
      ],
      "id": "ea742c4b-9ab8-4e16-a0c0-7ae727fac031"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "epsilon = 0.5\n",
        "threshold = 5\n",
        "psth[\"rel_spike_count_change\"] = (psth.spike_count - psth.baseline) / (\n",
        "    psth.baseline + epsilon\n",
        ")\n",
        "g = sns.relplot(\n",
        "    psth,\n",
        "    x=\"bin_time\",\n",
        "    y=\"rel_spike_count_change\",\n",
        "    units=\"unit_id\",\n",
        "    kind=\"line\",\n",
        "    estimator=None,\n",
        ")\n",
        "g.refline(y=threshold, color=\"black\", linestyle=\"--\", alpha=0.5)"
      ],
      "id": "cell-fig-relative_psth"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we group the data by unit ID and check whether each unit’s maximum\n",
        "value for the relative change in spike count is above the selected\n",
        "threshold. Then, we merge the result with the PSTH to get a new column\n",
        "with boolean values that indicate whether any given unit is responsive.\n",
        "Finally, we can reproduce\n",
        "<a href=\"#fig-baseline_psth\" class=\"quarto-xref\">Figure 3</a> selecting\n",
        "only the units that are responsive according to our threshold criterion."
      ],
      "id": "149e09f2-1920-4cb8-a8b7-dbb26ebf1a5f"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "is_responsive = psth.groupby([\"unit_id\"]).rel_spike_count_change.max() > threshold\n",
        "is_responsive.name = \"is_responsive\"\n",
        "psth = psth.merge(is_responsive, on=\"unit_id\")\n",
        "g = sns.relplot(\n",
        "    data=psth[psth.is_responsive],\n",
        "    x=\"bin_time\",\n",
        "    y=\"spike_count_change\",\n",
        "    kind=\"line\",\n",
        "    hue=\"brain_area\",\n",
        "    errorbar=None,\n",
        ")\n",
        "g.set(xlim=(-0.1, 0.5))"
      ],
      "id": "cell-fig-responsive_psth"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now the differences in response latency between the areas are much\n",
        "clearer. We can also make out some interesting trends — for example,\n",
        "units in V1 appear to respond mostly to the stimulus onset while units\n",
        "in LM respond more strongly to the offset.\n",
        "\n",
        "## Closing Remarks\n",
        "\n",
        "The goal of this post was to show how you can use Pandas and Seaborn to\n",
        "create detailed and informative graphs from large datasets (i.e. tables\n",
        "with hundreds of thousands of rows) with relatively little code. The\n",
        "methods for data aggregation, merging and visualization shown here will\n",
        "be applicable to any data that can be arranged in a tabular format. What\n",
        "this demo lacks is a statistical comparison of the spiking activity\n",
        "between brain areas. This was outside of the scope of this post since I\n",
        "only used data from a single animal. If you are interested in working\n",
        "with the full dataset you can check out my [GitHub\n",
        "repo](https://github.com/OleBialas/Ecephys-Recordings-from-Mouse-Visual-System)\n",
        "which contains the recordings from over 50 animals in the same data\n",
        "format used in this demo."
      ],
      "id": "b9c5babb-513b-47af-8caf-08dc2b8f186a"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/home/olebi/projects/new_website/.pixi/envs/default/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  }
}