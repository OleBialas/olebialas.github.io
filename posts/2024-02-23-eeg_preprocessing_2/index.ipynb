{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EEG preprocessing II: eye-artifacts, repairing and rejecting\n",
        "\n",
        "Ole Bialas  \n",
        "2024-02-23\n",
        "\n",
        "The [previous post on preprocessing EEG](posts/eeg_preprocessing)\n",
        "presented a minimally invasive pipeline of procedures that are necessary\n",
        "in most EEG analyses. In this post I present additional steps that might\n",
        "be useful if the data is still not **sufficiently cleaned**. First, I\n",
        "will address **eye blinks** which is one of the most prevalent sources\n",
        "of artifacts in EEG recordings. After that, I’ll demonstrate a method to\n",
        "repair or remove segments of the data **contaminated with noise**.\n",
        "\n",
        "# Prerequisites\n",
        "\n",
        "First, we need to install some packages that provide us with the equired\n",
        "preprocessing functions:\n",
        "\n",
        "    pip install mne meegkit pyprep autoreject\n",
        "\n",
        "Then, we have to dowload the sample data from MNE Python and clean it\n",
        "using the steps described [in the previous post on EEG\n",
        "preprocessing](posts/eeg_preprocessing). The code below does exactly\n",
        "that — if you want a more detailed explanation, read the original post.\n",
        "Running the cell below produces the cleaned `epochs` to which we will\n",
        "apply further preprocessing, starting with the removal of **eye\n",
        "artifacts**."
      ],
      "id": "8569ea45-d648-402d-8f1d-47b45dd46094"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from mne.io import read_raw_fif\n",
        "from mne.datasets.sample import data_path\n",
        "from mne import find_events\n",
        "from mne.epochs import Epochs\n",
        "from meegkit.detrend import detrend\n",
        "from meegkit.dss import dss_line\n",
        "from pyprep.ransac import find_bad_by_ransac\n",
        "\n",
        "raw = read_raw_fif(data_path() / \"MEG/sample/sample_audvis_raw.fif\")\n",
        "events = find_events(raw)\n",
        "raw.pick(picks=\"eeg\")\n",
        "raw, events = raw.resample(150, events=events)\n",
        "X = raw.get_data().T  # transpose so the data is organized time-by-channels\n",
        "X, _, _ = detrend(X, order=1)\n",
        "X, _, _ = detrend(X, order=6)\n",
        "raw._data = X.T  # overwrite raw data\n",
        "X, noise = dss_line(X, fline=60, sfreq=raw.info[\"sfreq\"], nremove=3)\n",
        "raw._data = X.T\n",
        "bads, _ = find_bad_by_ransac(\n",
        "    data=raw.get_data(),\n",
        "    sample_rate=raw.info[\"sfreq\"],\n",
        "    complete_chn_labs=np.asarray(raw.info[\"ch_names\"]),\n",
        "    chn_pos=np.stack([ch[\"loc\"][0:3] for ch in raw.info[\"chs\"]]),\n",
        "    exclude=[],\n",
        "    corr_thresh=0.9,\n",
        ")\n",
        "raw_clean = raw.copy()\n",
        "raw_clean.info[\"bads\"] = bads\n",
        "raw_clean.interpolate_bads()\n",
        "raw_clean.set_eeg_reference(\"average\", projection=True)  # compute the reference\n",
        "raw.add_proj(raw_clean.info[\"projs\"][0])\n",
        "del raw_clean  # delete the copy\n",
        "raw.apply_proj()  # apply the reference\n",
        "event_id = {\"auditory/left\": 1, \"auditory/right\": 2}\n",
        "epochs = Epochs(raw, events, event_id, tmin=-0.1, tmax=0.4, baseline=None, preload=True)"
      ],
      "id": "f95ddbcc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# What are eye artifacts?\n",
        "\n",
        "While it is often assumed that eye artifacts are the result of muscle\n",
        "activity, they are actually the result of a **ionic gradient** in the\n",
        "retinal pigment epithelium that makes the eye an **electric dipole**\n",
        "[1]. Thus, moving the eyes and the dipole **induces** a change in\n",
        "voltage picked up by the sensors that is roughly proportional to the\n",
        "**amplitude** of the movement. Because this could overshadow the neural\n",
        "responses, many studies eliminate eye movements by making participants\n",
        "**fixate** a point during the experiment.\n",
        "\n",
        "However, another kind of eye artifact may still occur - **blinks**. Eye\n",
        "blinks affect the measured voltage because the eye lid **changes the\n",
        "resistance** between the positively charged cornea and the forehead.\n",
        "Fortunately, these eye artifacts are largely **independent** of each\n",
        "other and the brain activity which makes them ideal candidates for\n",
        "independent component analysis (ICA) [2].\n",
        "\n",
        "# Identifying eye-blink components with ICA\n",
        "\n",
        "ICA is an algorithm that finds a rotation matrix to separate the sensor\n",
        "data into components that are **mutually independent** [3]. In the code\n",
        "below, I fit an ICA to the epoched data. At maximum, ICA can capture as\n",
        "many components as there are channels. However, usually the data can be\n",
        "captured with **fewer components**. When the `n_components` parameter is\n",
        "set to a decimal number, the ICA will compute as many components as are\n",
        "necessary to explain this share of the total variance in the data.\n",
        "Because highpass filtering improves the quality of artifact separation\n",
        "[4], I use a highpass filtered copy of the data for ICA.\n",
        "\n",
        "[1] This is referred to as the corneo-retinal dipole. A explanation of\n",
        "the underlying physiology can be found in: *Arden, G. B., & Constable,\n",
        "P. A. (2006). The electro-oculogram. Progress in retinal and eye\n",
        "research, 25(2), 207-248.*\n",
        "\n",
        "[2] A detailed investigation of eye-artifacts and their detection via\n",
        "ICA can be found in: *Plöchl, M., Ossandón, J. P., & König, P. (2012).\n",
        "Combining EEG and eye tracking: identification, characterization, and\n",
        "correction of eye movement artifacts in electroencephalographic data.\n",
        "Frontiers in human neuroscience, 6, 278.*\n",
        "\n",
        "[3] An in-depth explanation of ICA is beyond the scope of this post but\n",
        "can be found in: *Makeig, S., Bell, A., Jung, T. P., & Sejnowski, T. J.\n",
        "(1995). Independent component analysis of electroencephalographic data.\n",
        "Advances in neural information processing systems, 8.*\n",
        "\n",
        "[4] A highpass between 1 and 2 Hz before ICA is optimal, see *Winkler,\n",
        "I., Debener, S., Müller, K. R., & Tangermann, M. (2015, August). On the\n",
        "influence of high-pass filtering on ICA-based artifact reduction in\n",
        "EEG-ERP. In 2015 37th Annual International Conference of the IEEE\n",
        "Engineering in Medicine and Biology Society (EMBC) (pp. 4101-4105).\n",
        "IEEE.*"
      ],
      "id": "433f6c22-129c-462c-b390-dddec8cba945"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up high-pass filter at 2 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal highpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 2.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz)\n",
            "- Filter length: 249 samples (1.660 s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting ICA to data using 59 channels (please be patient, this may take a while)\n",
            "    Applying projection operator with 1 vector (pre-whitener computation)\n",
            "    Applying projection operator with 1 vector (pre-whitener application)\n",
            "Selecting by explained variance: 32 components\n",
            "    Applying projection operator with 1 vector (pre-whitener application)\n",
            "Fitting ICA took 4.6s."
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from mne.preprocessing import ICA\n",
        "fig, ax = plt.subplots(1, 5)\n",
        "ica = ICA(n_components=0.99)\n",
        "ica.fit(epochs.copy().filter(l_freq=2, h_freq=None))\n",
        "ica.plot_components(range(5), axes=ax);"
      ],
      "id": "e8d8372f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The components are ordered by **explained variance**, so the first few\n",
        "components have the largest impact on the signal. Each component is a\n",
        "**linear combination** of all channels and the weights indicate how much\n",
        "each channel affects that component [1]. The first components depends\n",
        "almost solely on the **frontal channels** - a strong indicator that it\n",
        "represents eye-blink artifacts!\n",
        "\n",
        "Another way to characterize the components is to obtain their **time\n",
        "course** by filtering the EEG signal using the component weights. The\n",
        "resulting time series is called the **component loading** and indicates\n",
        "the presence of that component in the data across time. In the code\n",
        "below, I compute the loading for all ICA components, select the first\n",
        "one and plot it after concatenating all epochs.\n",
        "\n",
        "[1] The absolute sign of the component is meaningless and may change\n",
        "when ICA is performed repeatedly."
      ],
      "id": "a44dc221-6692-4f7b-abfb-a291fa05b9ff"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Applying projection operator with 1 vector (pre-whitener application)"
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "src = ica.get_sources(epochs)\n",
        "src = src.get_data()[:, 0, :].flatten()\n",
        "times = np.linspace(0, len(src) / epochs.info[\"sfreq\"], len(src))\n",
        "plt.plot(times[:4000], src[:4000])\n",
        "plt.xlabel(\"Time [s]\")\n",
        "plt.ylabel(\"Component loading [a.u.]\");"
      ],
      "id": "7fb660d6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The component loading is mostly flat except for **large amplitude\n",
        "spikes** - exactly what is expected from a signal that represents\n",
        "discrete eye blinks. After ensuring that the component captures blinks\n",
        "it can be removed from the data.\n",
        "\n",
        "# Automated component rejection\n",
        "\n",
        "One could simply select and remove the eye blink component from the\n",
        "data. However, manual selection of components goes against the idea of\n",
        "an automated preprocessing pipeline. Instead, we can use the selected\n",
        "component as a **template** and classify new components as blinks by\n",
        "using the `corrmap` algorithm which selects components who’s\n",
        "**correlation** with the template exceeds some **threshold** [1]. To do\n",
        "this we can can store the blink component’s index in the `ICA.labels_`\n",
        "attribute and save the ICA as template.\n",
        "\n",
        "[1] A detailed description of the corrmap algorithm can be found in\n",
        "*Viola, F. C., Thorne, J., Edmonds, B., Schneider, T., Eichele, T., &\n",
        "Debener, S. (2009). Semi-automatic identification of independent\n",
        "components representing EEG artifact. Clinical Neurophysiology, 120(5),\n",
        "868-877.*"
      ],
      "id": "b39c6f3e-3651-41c1-9ce6-986f2c715bb3"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ICA solution to /tmp/tmpt5eat6l_/template_ica.fif..."
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "import tempfile\n",
        "temp_dir = tempfile.TemporaryDirectory()\n",
        "template = ica.copy()\n",
        "template.labels_['blinks'] = [0]\n",
        "template.save(temp_dir.name + '/template_ica.fif')"
      ],
      "id": "263d5665"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can iterate through all entries in the `.labels_` attribute and\n",
        "use `corrmap` to find components that are **similar** to the respective\n",
        "template. The first input for `corrmap` is the list of ICAs being\n",
        "processed. The second input is a tuple with the index of the ICA\n",
        "instance in the list and the component of that ICA being used as\n",
        "**template**. Similar components that are detected are stored in the\n",
        "`.labels_` attribute of the respective ICA instance."
      ],
      "id": "443ab76e-08df-41ae-897d-1b04b331be24"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading /tmp/tmpt5eat6l_/template_ica.fif ...\n",
            "    Read a total of 1 projection items:\n",
            "        Average EEG reference (1 x 60) active\n",
            "Now restoring ICA solution ...\n",
            "Ready.\n",
            "Median correlation with constructed map: 1.000\n",
            "At least 1 IC detected for each subject."
          ]
        }
      ],
      "source": [
        "from mne.preprocessing import read_ica, corrmap\n",
        "template = read_ica(temp_dir.name + '/template_ica.fif')\n",
        "\n",
        "for key, value in template.labels_.items():\n",
        "    corrmap([template, ica], (0, value[0]), label=key, threshold=0.85, plot=False)"
      ],
      "id": "1615a244"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Of course, this example is completely circular because we applied\n",
        "`corrmap` to the same data we used for selecting the template in the\n",
        "first place. However, once selected, the same template can be applied to\n",
        "**multiple recorings** and even **across experiments**, given that the\n",
        "electrode layout is the same. After all artifact components have been\n",
        "identified, we can exclude them when **applying** the ICA to the sensor\n",
        "data."
      ],
      "id": "99fb28ad-3598-4650-8169-3b391e8df936"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying ICA to Epochs instance\n",
            "    Applying projection operator with 1 vector (pre-whitener application)\n",
            "    Transforming to ICA space (32 components)\n",
            "    Zeroing out 1 ICA component\n",
            "    Projecting back using 59 PCA components"
          ]
        }
      ],
      "source": [
        "bad_components = [value[0] for value in ica.labels_.values()]\n",
        "epochs.load_data() # make sure data is loaded\n",
        "epochs = ica.apply(epochs, exclude=bad_components)"
      ],
      "id": "47394ad3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# When data must be rejected\n",
        "\n",
        "Even with all the preprocessing steps discussed in this guide, some data\n",
        "can’t be saved. Sometimes, a channels **loses contact** with the scalp\n",
        "or a segment is noise-ridden, for example due to **excessive movement**.\n",
        "In those cases, we have to remove that data so it won’t **contaminate**\n",
        "the average response. Traditionally, EEG data is **manually inspected**,\n",
        "bad channels are interpolated and bad segments are annotated for\n",
        "rejection by hand. This is suboptimal for several reasons: first,\n",
        "scanning tens of hours of EEG recordings is tedious, **time consuming**\n",
        "and unfeasible for very large data sets. What’s more, the manual\n",
        "approach **reduces reproducibility** because the criteria for what\n",
        "counts as a bad channel or segment are subjective. Finally, it is often\n",
        "not necessary to interpolate a channel for the entire recording if it is\n",
        "bad for **only a fraction**.\n",
        "\n",
        "# Introducing autoreject\n",
        "\n",
        "All of these problems are addressed by the `autoreject` algorithm [1],\n",
        "which is a procedure to identify and either **repair or reject** bad\n",
        "data segments. For each channel p, it estimates a peak-to-peak\n",
        "**threshold** τ. Each channel marks epochs as bad that exceeds their\n",
        "respective threshold. A trial is rejected if a **fraction κ** of all\n",
        "channels marks it as bad. If less than κ channels are bad, up to **ρ are\n",
        "interpolated** to repair the epoch. All parameters, τ κ and ρ are\n",
        "**estimated from the data** using cross-validation. Thus the optimal set\n",
        "of parameters are those that **minimize the difference** between testing\n",
        "and training data. In this sense, `autoreject` acts similar to a **human\n",
        "observer** identifying outliers in the data. After installing the module\n",
        "with `pip install autoreject`, we can simply apply it to the epoched\n",
        "data. I also plot the **rejection log** to visualize the effect of\n",
        "`autoreject` on the data.\n",
        "\n",
        "[1] A detailed description of the autoreject algorithm can be found in\n",
        "*Jas, M., Engemann, D. A., Bekhti, Y., Raimondo, F., & Gramfort, A.\n",
        "(2017). Autoreject: Automated artifact rejection for MEG and EEG data.\n",
        "NeuroImage, 159, 417-429.*"
      ],
      "id": "5e51cc30-d655-44c7-ad42-13f54b34adc5"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped 5 epochs: 32, 40, 95, 96, 103"
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {}
        }
      ],
      "source": [
        "from autoreject import AutoReject\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ar = AutoReject(verbose=False)\n",
        "epochs, log = ar.fit_transform(epochs, return_log=True)\n",
        "log.plot(orientation=\"horizontal\", ax=ax);"
      ],
      "id": "1675e42f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the plot below, blue marks channels that have been **interpolated**\n",
        "within a given epoch. Red marks channels that have been deemed bad but\n",
        "not interpolated because the number of bad channels **exceeded ρ**. The\n",
        "red column at epoch 40 indicates that this epoch has been **rejected**\n",
        "because the number of bad channels **exceeded κ**.\n",
        "\n",
        "# Conclusion\n",
        "\n",
        "The repertoire of preprocessing methods outlined in this and the\n",
        "previous post is sufficient to clean data for most EEG projects.\n",
        "Importantly, all steps can be assembled into a **fully automated**\n",
        "pipeline. In the next and final post in this series, I will share a such\n",
        "a pipeline and demonstrate a method for estimating the **effectiveness**\n",
        "of each step.\n",
        "\n",
        "# Footnotes"
      ],
      "id": "c5864ff6-7238-43e5-9de3-e4fa947ee9f6"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/home/olebi/projects/new_website/.pixi/envs/default/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "state": {
          "04e776a215db4bf4a078c23365a0a8ae": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "model_name": "HTMLModel",
            "state": {
              "_dom_classes": [],
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "2.0.0",
              "_model_name": "HTMLModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/controls",
              "_view_module_version": "2.0.0",
              "_view_name": "HTMLView",
              "description": "",
              "description_allow_html": false,
              "layout": "IPY_MODEL_2e2a1469913b49f480314dbf0e8e32b2",
              "placeholder": "​",
              "style": "IPY_MODEL_d256099e875e4376bba33baa7b3b1743",
              "tabbable": null,
              "tooltip": null,
              "value": "100%"
            }
          },
          "2e2a1469913b49f480314dbf0e8e32b2": {
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "2.0.0",
            "model_name": "LayoutModel",
            "state": {
              "_model_module": "@jupyter-widgets/base",
              "_model_module_version": "2.0.0",
              "_model_name": "LayoutModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "2.0.0",
              "_view_name": "LayoutView",
              "align_content": null,
              "align_items": null,
              "align_self": null,
              "border_bottom": null,
              "border_left": null,
              "border_right": null,
              "border_top": null,
              "bottom": null,
              "display": null,
              "flex": null,
              "flex_flow": null,
              "grid_area": null,
              "grid_auto_columns": null,
              "grid_auto_flow": null,
              "grid_auto_rows": null,
              "grid_column": null,
              "grid_gap": null,
              "grid_row": null,
              "grid_template_areas": null,
              "grid_template_columns": null,
              "grid_template_rows": null,
              "height": null,
              "justify_content": null,
              "justify_items": null,
              "left": null,
              "margin": null,
              "max_height": null,
              "max_width": null,
              "min_height": null,
              "min_width": null,
              "object_fit": null,
              "object_position": null,
              "order": null,
              "overflow": null,
              "padding": null,
              "right": null,
              "top": null,
              "visibility": null,
              "width": null
            }
          },
          "32e8435fe0374d17990f7d034c26c506": {
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "2.0.0",
            "model_name": "LayoutModel",
            "state": {
              "_model_module": "@jupyter-widgets/base",
              "_model_module_version": "2.0.0",
              "_model_name": "LayoutModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "2.0.0",
              "_view_name": "LayoutView",
              "align_content": null,
              "align_items": null,
              "align_self": null,
              "border_bottom": null,
              "border_left": null,
              "border_right": null,
              "border_top": null,
              "bottom": null,
              "display": null,
              "flex": null,
              "flex_flow": null,
              "grid_area": null,
              "grid_auto_columns": null,
              "grid_auto_flow": null,
              "grid_auto_rows": null,
              "grid_column": null,
              "grid_gap": null,
              "grid_row": null,
              "grid_template_areas": null,
              "grid_template_columns": null,
              "grid_template_rows": null,
              "height": null,
              "justify_content": null,
              "justify_items": null,
              "left": null,
              "margin": null,
              "max_height": null,
              "max_width": null,
              "min_height": null,
              "min_width": null,
              "object_fit": null,
              "object_position": null,
              "order": null,
              "overflow": null,
              "padding": null,
              "right": null,
              "top": null,
              "visibility": null,
              "width": null
            }
          },
          "4011ca556686447882c684246680de92": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "model_name": "ProgressStyleModel",
            "state": {
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "2.0.0",
              "_model_name": "ProgressStyleModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "2.0.0",
              "_view_name": "StyleView",
              "bar_color": null,
              "description_width": ""
            }
          },
          "7b20405c32804137a5af52f584fdfd59": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "model_name": "HTMLModel",
            "state": {
              "_dom_classes": [],
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "2.0.0",
              "_model_name": "HTMLModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/controls",
              "_view_module_version": "2.0.0",
              "_view_name": "HTMLView",
              "description": "",
              "description_allow_html": false,
              "layout": "IPY_MODEL_851d2b0c7945478eb263274910521dd1",
              "placeholder": "​",
              "style": "IPY_MODEL_8f05374fa4db4f7dbcf9ab35a490651a",
              "tabbable": null,
              "tooltip": null,
              "value": "  : 55/55 [00:05&lt;00:00,    8.50it/s]"
            }
          },
          "851d2b0c7945478eb263274910521dd1": {
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "2.0.0",
            "model_name": "LayoutModel",
            "state": {
              "_model_module": "@jupyter-widgets/base",
              "_model_module_version": "2.0.0",
              "_model_name": "LayoutModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "2.0.0",
              "_view_name": "LayoutView",
              "align_content": null,
              "align_items": null,
              "align_self": null,
              "border_bottom": null,
              "border_left": null,
              "border_right": null,
              "border_top": null,
              "bottom": null,
              "display": null,
              "flex": null,
              "flex_flow": null,
              "grid_area": null,
              "grid_auto_columns": null,
              "grid_auto_flow": null,
              "grid_auto_rows": null,
              "grid_column": null,
              "grid_gap": null,
              "grid_row": null,
              "grid_template_areas": null,
              "grid_template_columns": null,
              "grid_template_rows": null,
              "height": null,
              "justify_content": null,
              "justify_items": null,
              "left": null,
              "margin": null,
              "max_height": null,
              "max_width": null,
              "min_height": null,
              "min_width": null,
              "object_fit": null,
              "object_position": null,
              "order": null,
              "overflow": null,
              "padding": null,
              "right": null,
              "top": null,
              "visibility": null,
              "width": null
            }
          },
          "8f05374fa4db4f7dbcf9ab35a490651a": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "model_name": "HTMLStyleModel",
            "state": {
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "2.0.0",
              "_model_name": "HTMLStyleModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "2.0.0",
              "_view_name": "StyleView",
              "background": null,
              "description_width": "",
              "font_size": null,
              "text_color": null
            }
          },
          "9d68795ec2e14ca2b044307dbd187122": {
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "2.0.0",
            "model_name": "LayoutModel",
            "state": {
              "_model_module": "@jupyter-widgets/base",
              "_model_module_version": "2.0.0",
              "_model_name": "LayoutModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "2.0.0",
              "_view_name": "LayoutView",
              "align_content": null,
              "align_items": null,
              "align_self": null,
              "border_bottom": null,
              "border_left": null,
              "border_right": null,
              "border_top": null,
              "bottom": null,
              "display": null,
              "flex": null,
              "flex_flow": null,
              "grid_area": null,
              "grid_auto_columns": null,
              "grid_auto_flow": null,
              "grid_auto_rows": null,
              "grid_column": null,
              "grid_gap": null,
              "grid_row": null,
              "grid_template_areas": null,
              "grid_template_columns": null,
              "grid_template_rows": null,
              "height": null,
              "justify_content": null,
              "justify_items": null,
              "left": null,
              "margin": null,
              "max_height": null,
              "max_width": null,
              "min_height": null,
              "min_width": null,
              "object_fit": null,
              "object_position": null,
              "order": null,
              "overflow": null,
              "padding": null,
              "right": null,
              "top": null,
              "visibility": null,
              "width": null
            }
          },
          "c6d7a6f1e8e244018e4d3680af87b4d2": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "model_name": "FloatProgressModel",
            "state": {
              "_dom_classes": [],
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "2.0.0",
              "_model_name": "FloatProgressModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/controls",
              "_view_module_version": "2.0.0",
              "_view_name": "ProgressView",
              "bar_style": "success",
              "description": "",
              "description_allow_html": false,
              "layout": "IPY_MODEL_9d68795ec2e14ca2b044307dbd187122",
              "max": 55,
              "min": 0,
              "orientation": "horizontal",
              "style": "IPY_MODEL_4011ca556686447882c684246680de92",
              "tabbable": null,
              "tooltip": null,
              "value": 55
            }
          },
          "d256099e875e4376bba33baa7b3b1743": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "model_name": "HTMLStyleModel",
            "state": {
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "2.0.0",
              "_model_name": "HTMLStyleModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "2.0.0",
              "_view_name": "StyleView",
              "background": null,
              "description_width": "",
              "font_size": null,
              "text_color": null
            }
          },
          "d8e30a0499e64359a124919b4d06e934": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "2.0.0",
            "model_name": "HBoxModel",
            "state": {
              "_dom_classes": [],
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "2.0.0",
              "_model_name": "HBoxModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/controls",
              "_view_module_version": "2.0.0",
              "_view_name": "HBoxView",
              "box_style": "",
              "children": [
                "IPY_MODEL_04e776a215db4bf4a078c23365a0a8ae",
                "IPY_MODEL_c6d7a6f1e8e244018e4d3680af87b4d2",
                "IPY_MODEL_7b20405c32804137a5af52f584fdfd59"
              ],
              "layout": "IPY_MODEL_32e8435fe0374d17990f7d034c26c506",
              "tabbable": null,
              "tooltip": null
            }
          }
        },
        "version_major": 2,
        "version_minor": 0
      }
    }
  }
}