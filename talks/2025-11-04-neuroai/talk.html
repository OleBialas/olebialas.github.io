<!DOCTYPE html>
<html lang="en"><head>
<link href="../..//assets/images/logo.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/quarto-contrib/qrcodejs-v1.0.0/qrcode.js"></script>
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.25">

  <meta name="author" content="Ole Bialas">
  <meta name="dcterms.date" content="2025-11-04">
  <title>OBi – What’s “neural” about neural networks?</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-299503c37b53ae82c618e782493c6ce9.css">
  <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZG4WYHJ56T"></script>

  <script type="text/javascript">

  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
   
    gtag('consent', 'default', {
      'ad_storage': 'denied',
      'analytics_storage': 'denied'
    });
  gtag('config', 'G-ZG4WYHJ56T', { 'anonymize_ip': true});
  </script>
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
<meta property="og:title" content="What’s “neural” about neural networks? – OBi">
<meta property="og:description" content="On the similarities and differences between artificial and natural intelligence">
<meta property="og:image" content="https://olebialas.github.io/talks/2025-11-04-neuroai/data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==">
<meta property="og:site_name" content="OBi">
<meta name="twitter:title" content="What’s “neural” about neural networks? – OBi">
<meta name="twitter:description" content="On the similarities and differences between artificial and natural intelligence">
<meta name="twitter:image" content="https://olebialas.github.io/talks/2025-11-04-neuroai/data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==">
<meta name="twitter:card" content="summary_large_image">
</head>
<body class="quarto-light">
<script src="mathjax-config.js"></script>
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">What’s “neural” about neural networks?</h1>
  <p class="subtitle">On the similarities and differences between artificial and natural intelligence</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Ole Bialas <a href="https://orcid.org/0000-0000-0000-0000" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
</div>
<div class="quarto-title-author-email">
<a href="mailto:bialas@uni-bonn.de">bialas@uni-bonn.de</a>
</div>
        <p class="quarto-title-affiliation">
            iBehave Open Technology Support (iBOTS)
          </p>
    </div>
</div>

  <p class="date">November 4, 2025</p>
</section>
<section id="agenda" class="slide level2">
<h2>Agenda</h2>
<ul>
<li class="fragment">The (historical) relationship between neuroscience and AI</li>
<li class="fragment">Why AI researchers should care about neuroscience</li>
<li class="fragment">How to compare ANNs and brains</li>
<li class="fragment">Fundamental difference between ANNs and intelligent biological agents</li>
</ul>
<div style="position: absolute; bottom: 0px; left: 50%; transform: translateX(-50%); text-align: center;">
<p></p><div id="" class="qrcode"></div>
<script type="text/javascript">
(function() {
  var script = document.currentScript;
  var qrcode = script.previousElementSibling;
  qrcode.qrcode = new QRCode(qrcode, {"colorDark":"#000000","colorLight":"#ffffff","height":"250","text":"https://olebialas.github.io","width":"250"});
  script.remove();
})();
</script>
     <br> <a href="https://olebialas.github.io">olebialas.github.io</a><p></p>
</div>
</section>
<section id="how-it-started" class="slide level2">
<h2>How it started …</h2>
<div class="fragment">
<div class="columns">
<div class="column" style="width:40%;">
<figure style="display: inline-block; text-align: center; margin: 0px 20px 20px 20px;">
<img src="https://historyofinformation.com/images/Screen_Shot_2020-09-09_at_6.46.46_AM_big.png" style="border-radius: 50%; width: 250px; height: 250px; object-fit: cover;">
</figure>
</div><div class="column" style="width:60%;">
<p><strong>Neural computation</strong>: neurons can implement logical operations and networks of such neurons are capable of universal computation <span class="citation" data-cites="mcculloch1943">(<a href="#/section-1" role="doc-biblioref" onclick="">McCulloch and Pitts 1943</a>)</span>.</p>
</div></div>
</div>
<div class="fragment">
<div class="columns">
<div class="column" style="width:40%;">
<figure style="display: inline-block; text-align: center; margin: 0px 20px 20px 20px;">
<img src="https://d3d0lqu00lnqvz.cloudfront.net/donaldoldinghebb/donaldhebb.jpg" style="border-radius: 50%; width: 250px; height: 250px; object-fit: cover;">
</figure>
</div><div class="column" style="margin-top: 20px;">
<p><strong>Hebbian learning</strong>: Randomly wired networks can learn through input driven reinforcement of synaptic connections <span class="citation" data-cites="hebb1949">(<a href="#/section-1" role="doc-biblioref" onclick="">Hebb 1949</a>)</span></p>
</div></div>
</div>
</section>
<section id="how-its-going" class="slide level2">
<h2>How it’s going…</h2>

<img src="https://i.imgflip.com/a9nfqq.jpg" class="r-stretch"></section>
<section>
<section id="you-cant-brute-force-intelligence" class="title-slide slide level1 center">
<h1>You can’t brute force intelligence</h1>

</section>
<section id="what-is-intelligence" class="slide level2">
<h2>What is Intelligence ?</h2>
<ul>
<li class="fragment"><strong>Skill</strong> is how is the ability to perform a given task (e.g.&nbsp;playing chess)</li>
<li class="fragment"><strong>Intelligence</strong> is the ability to acquire-new skills and generalize to new problems <span class="citation" data-cites="chollet2019">(<a href="#/section-1" role="doc-biblioref" onclick="">Chollet 2019</a>)</span></li>
<li class="fragment">The Abstraction and Reasoning Corpus (<strong>ARC</strong>) is a set of tests aiming to benchmark intelligence (<a href="https://arcprize.org/leaderboard">ARC leaderboard</a>)</li>
</ul>
</section>
<section id="example-of-an-arc-task" class="slide level2">
<h2>Example of an ARC task</h2>
<figure style="text-align: center;">
<img src="https://arcprize.org/media/images/blog/arc-agi-2-unsolved-1.png">
<figcaption>
ARC-AGI-2 Public Eval Task #e3721c99
</figcaption>
</figure>
</section></section>
<section>
<section id="comparing-brains-and-neural-networks" class="title-slide slide level1 center">
<h1>Comparing Brains and Neural Networks</h1>

</section>
<section id="relating-model-activation-to-brain-recordings" class="slide level2">
<h2>Relating Model Activation to Brain Recordings</h2>
<ul>
<li class="fragment">Show the same stimuli (e.g images) to Humans and Models</li>
<li class="fragment">Find mapping <span class="math inline">\(W\)</span> between brain activity <span class="math inline">\(Y\)</span> and model activation <span class="math inline">\(X\)</span></li>
<li class="fragment">Correlate the prediction from model activation to the actual brain recording: <span class="math inline">\(R^{(d)} = \text{corr}(WX_{test}, y_{test})\)</span></li>
</ul>
<div class="fragment">
<figure style="text-align: center;">
<img src="https://arxiv.org/html/2508.18226v1/Figures_DinoxBrain/fig1.png">
<figcaption style="margin-top: -20px;">
<span class="citation" data-cites="raugel2025">Raugel et al. (<a href="#/section-1" role="doc-biblioref" onclick="">2025</a>)</span>: Disentangling factors of convergence between brains and computer vision models
</figcaption>
</figure>
</div>
</section>
<section id="corresponding-representational-hierarchies" class="slide level2">
<h2>Corresponding Representational Hierarchies</h2>
<div class="fragment">
<ul>
<li>Early and late layers align with the earliest and latest brain responses
<div style="text-align: center; margin-top: -20px; margin-bottom: -40px">
<p><a href="img/temporal.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img data-src="img/temporal.png" width="650"></a></p>
</div></li>
</ul>
</div>
<div class="fragment">
<ul>
<li>Early and late layers map onto lower-level and higher-level regions
<div style="text-align: center; margin-top: -20px; margin-bottom: -40px">
<p><a href="img/spatial.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img data-src="img/spatial.png" width="650"></a></p>
</div></li>
</ul>
</div>
</section>
<section id="different-architecture-convergent-solutions" class="slide level2">
<h2>Different Architecture, Convergent Solutions</h2>
<div class="columns">
<div class="column">
<div class="fragment">
<ul>
<li>Better ImageNets are more predictive of brain activity
<figure style="text-align: center;">
<img src="img/b_score.png" style="height: 400px;">
<figcaption style="font-size: 14px; margin-top: 5px;">
<span class="citation" data-cites="schrimpf2018">Schrimpf et al. (<a href="#/section-1" role="doc-biblioref" onclick="">2018</a>)</span>: Brain-score: Which artificial neural network for object recognition is most brain-like?
</figcaption>
</figure></li>
</ul>
</div>
</div><div class="column">
<div class="fragment">
<ul>
<li>Not every model maps onto the neural hierarchy
<figure style="text-align: center;">
<img src="img/bh_score.jpg" style="height: 400px;">
<figcaption style="font-size: 14px; margin-top: 5px;">
<span class="citation" data-cites="nonaka2021">Nonaka et al. (<a href="#/section-1" role="doc-biblioref" onclick="">2021</a>)</span>: Brain hierarchy score: Which deep neural networks are hierarchically brain-like?
</figcaption>
</figure></li>
</ul>
</div>
</div></div>
</section>
<section id="comparing-humand-and-model-behavior" class="slide level2">
<h2>Comparing Humand and Model Behavior</h2>
<div class="fragment">
<div style="text-align: center; margin-top: -20px">
<p><img src="img/odd-one-out.png" width="650"></p>
</div>
</div>
<div class="fragment">
<figure style="text-align: center; margin-top: -20px">
<img src="img/dimensions.png" width="650">
<figcaption style="font-size: 14px; margin-top: -10px;">
<span class="citation" data-cites="hebart2020">Hebart et al. (<a href="#/section-1" role="doc-biblioref" onclick="">2020</a>)</span>: Revealing the multidimensional mental representations of natural objects underlying human similarity judgements
</figcaption>
</figure>
</div>
</section>
<section id="different-dimensions-of-interest" class="slide level2">
<h2>Different Dimensions of Interest</h2>
<figure style="text-align: center; margin-top: -20px">
<img src="img/ai-dimensions.png" width="800">
<figcaption style="font-size: 14px; margin-top: -10px;">
<span class="citation" data-cites="mahner2025">Mahner et al. (<a href="#/section-1" role="doc-biblioref" onclick="">2025</a>)</span>: Dimensions underlying the representational alignment of deep neural networks with humans
</figcaption>
</figure>
</section></section>
<section>
<section id="fundamental-differences-between-artifical-and-biological-intelligence" class="title-slide slide level1 center">
<h1>Fundamental Differences between Artifical and Biological Intelligence</h1>

</section>
<section id="emodied-cognition" class="slide level2">
<h2>Emodied Cognition</h2>
<div class="columns">
<div class="column">
<div class="fragment" data-fragment-index="1">
<ul>
<li>AI is purely computational/statistical inference but human cognition is physically embodied</li>
</ul>
</div>
<div class="fragment" data-fragment-index="2">
<ul>
<li>Human cognition can extend beyond the brain into the body and environment</li>
</ul>
</div>
<div class="fragment" data-fragment-index="3">
<ul>
<li>Example: the gaze heuristic</li>
</ul>
</div>
</div><div class="column">
<div class="fragment" data-fragment-index="3">
<figure style="text-align: center; margin-top: -50px">
<img src="https://www.frontiersin.org/files/Articles/711289/fpsyg-12-711289-HTML/image_m/fpsyg-12-711289-g002.jpg" width="400">
<figcaption style="font-size: 14px; margin-top: 60px;">
<span class="citation" data-cites="gigerenzer2021">Gigerenzer (<a href="#/section-1" role="doc-biblioref" onclick="">2021</a>)</span>: Embodied Heuristics
</figcaption>
</figure>
</div>
</div></div>
<div class="fragment" data-fragment-index="4">
<ul>
<li>Because human cognition is embodied, <strong>complicated inference</strong> problems can be solved by <strong>simple heuristics</strong></li>
</ul>
</div>
</section>
<section id="are-ai-agents-real-agents" class="slide level2">
<h2>Are AI “Agents” Real Agents?</h2>
<div class="columns">
<div class="column">
<p><strong>Biological Agents</strong></p>
<div class="fragment" data-fragment-index="1">
<ul>
<li>Are <strong>autopoietic</strong> (i.e.&nbsp;self-manufacturing)</li>
</ul>
</div>
<div class="fragment" data-fragment-index="2">
<ul>
<li>Are <strong>internally motivated</strong> to self-preserve and act autonomously</li>
</ul>
</div>
<div class="fragment" data-fragment-index="3">
<ul>
<li>Live in a large world of <strong>ill-defined</strong> problems and have to decide what is relevant</li>
</ul>
</div>
</div><div class="column">
<p><strong>Artificial Agents</strong></p>
<div class="fragment" data-fragment-index="1">
<ul>
<li>Are programmed by an <strong>external agent</strong></li>
</ul>
</div>
<div class="fragment" data-fragment-index="2">
<ul>
<li>Are <strong>externally motivated</strong> and triggered by an external agent</li>
</ul>
</div>
<div class="fragment" data-fragment-index="3">
<ul>
<li>Live in a small world of <strong>well-defined</strong> problems and operate within <strong>predefined</strong> formalized ontology</li>
</ul>
</div>
</div></div>
<div class="fragment">
<p>See <span class="citation" data-cites="jaeger2024">Jaeger et al. (<a href="#/section-1" role="doc-biblioref" onclick="">2024</a>)</span>: Naturalizing relevance realization: why agency and cognition are fundamentally not computational</p>
</div>
</section>
<section id="section" class="slide level2" data-background-color="black" data-background-image="https://techcrunch.com/wp-content/uploads/2015/11/humanrobotoverlap.jpg">
<h2></h2>
<div style="position: absolute; top: 25%; left: 50%; transform: translate(-50%, -50%); color: black; font-size: 2.5em; text-align: center;">
<p>Thank<br>you</p>
</div>
<div style="position: absolute; bottom: 0px; right: -40px; color: white; font-size: 14px">
<p>Image Credits: <a href="www.shutterstock.com/g/razumhttp://www.shutterstock.com/gallery-935953p1.html" style="color: white;">razum</a> /<a href="https://www.shutterstock.com/" style="color: white;">Shutterstock</a></p>
</div>
</section>
<section id="section-1" class="slide level2 smaller scrollable" data-visibility="uncounted">
<h2></h2>
<p>References</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-chollet2019" class="csl-entry" role="listitem">
Chollet, François. 2019. <span>“On the Measure of Intelligence.”</span> <em>arXiv Preprint arXiv:1911.01547</em>.
</div>
<div id="ref-gigerenzer2021" class="csl-entry" role="listitem">
Gigerenzer, Gerd. 2021. <span>“Embodied Heuristics.”</span> <em>Frontiers in Psychology</em> 12: 711289.
</div>
<div id="ref-hebart2020" class="csl-entry" role="listitem">
Hebart, Martin N, Charles Y Zheng, Francisco Pereira, and Chris I Baker. 2020. <span>“Revealing the Multidimensional Mental Representations of Natural Objects Underlying Human Similarity Judgements.”</span> <em>Nature Human Behaviour</em> 4 (11): 1173–85.
</div>
<div id="ref-hebb1949" class="csl-entry" role="listitem">
Hebb, DO. 1949. <span>“The Organization of Behavior. A Neuropsychological Theory.”</span>
</div>
<div id="ref-jaeger2024" class="csl-entry" role="listitem">
Jaeger, Johannes, Anna Riedl, Alex Djedovic, John Vervaeke, and Denis Walsh. 2024. <span>“Naturalizing Relevance Realization: Why Agency and Cognition Are Fundamentally Not Computational.”</span> <em>Frontiers in Psychology</em> 15: 1362658.
</div>
<div id="ref-mahner2025" class="csl-entry" role="listitem">
Mahner, Florian P, Lukas Muttenthaler, Umut Güçlü, and Martin N Hebart. 2025. <span>“Dimensions Underlying the Representational Alignment of Deep Neural Networks with Humans.”</span> <em>Nature Machine Intelligence</em> 7 (6): 848–59.
</div>
<div id="ref-mcculloch1943" class="csl-entry" role="listitem">
McCulloch, Warren S, and Walter Pitts. 1943. <span>“A Logical Calculus of the Ideas Immanent in Nervous Activity.”</span> <em>The Bulletin of Mathematical Biophysics</em> 5 (4): 115–33.
</div>
<div id="ref-nonaka2021" class="csl-entry" role="listitem">
Nonaka, Soma, Kei Majima, Shuntaro C Aoki, and Yukiyasu Kamitani. 2021. <span>“Brain Hierarchy Score: Which Deep Neural Networks Are Hierarchically Brain-Like?”</span> <em>IScience</em> 24 (9).
</div>
<div id="ref-raugel2025" class="csl-entry" role="listitem">
Raugel, Joséphine, Marc Szafraniec, Huy V Vo, Camille Couprie, Patrick Labatut, Piotr Bojanowski, Valentin Wyart, and Jean-Rémi King. 2025. <span>“Disentangling the Factors of Convergence Between Brains and Computer Vision Models.”</span> <em>arXiv Preprint arXiv:2508.18226</em>.
</div>
<div id="ref-schrimpf2018" class="csl-entry" role="listitem">
Schrimpf, Martin, Jonas Kubilius, Ha Hong, Najib J Majaj, Rishi Rajalingham, Elias B Issa, Kohitij Kar, et al. 2018. <span>“Brain-Score: Which Artificial Neural Network for Object Recognition Is Most Brain-Like?”</span> <em>BioRxiv</em>, 407007.
</div>
</div>
</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/olebialas\.github\.io\/");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    <script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
    (function() {
      let previousOnload = window.onload;
      window.onload = () => {
        if (previousOnload) {
          previousOnload();
        }
        lightboxQuarto.on('slide_before_load', (data) => {
          const { slideIndex, slideNode, slideConfig, player, trigger } = data;
          const href = trigger.getAttribute('href');
          if (href !== null) {
            const imgEl = window.document.querySelector(`a[href="${href}"] img`);
            if (imgEl !== null) {
              const srcAttr = imgEl.getAttribute("src");
              if (srcAttr && srcAttr.startsWith("data:")) {
                slideConfig.href = srcAttr;
              }
            }
          } 
        });
      
        lightboxQuarto.on('slide_after_load', (data) => {
          const { slideIndex, slideNode, slideConfig, player, trigger } = data;
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(slideNode);
          }
        });
      
      };
      
    })();
              </script>
    

</body></html>