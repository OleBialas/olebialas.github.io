{
  "hash": "caa7668be6443955b007edc9fa0ef2ff",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Surveying Neural Spiking in Visual Cortex with Pandas and Seaborn\"\ndescription: \"In this post, I'll demonstrate how to use the Python libraries Pandas and Seaborn to ananlyze and plot spiking data from hundreds of neurons located in different areas of the visual cortex.\"\ndate: \"2025-09-03\"\nimage: featured.png\nimage-alt: |\n    \"`matplotlib` figure of peri-stimulus time histogram across brain areas\"\naliases:\n  - /post/surveying-spiking/index.html\n  - /post/surveying-spiking.html\nengine: Jupyter\nformat:\n  html: default\n  ipynb: default\nfreeze: auto\n---\n\nModern electrophysiology equipment like the [Neuropixels probes](https://en.wikipedia.org/wiki/Neuropixels) allows for simultaneous recording of hundreds of neurons.\nThis leaves researchers with massive amounts of data to process and visualize.\nFortunately, the Python ecosystem provides powerful tools for generating beautiful visualizations from large amounts of data in only a few lines of code.\nIn this post, I'll use data from a [2021 study by Joshua Siegle and colleagues](https://www.nature.com/articles/s41586-020-03171-x)[^1], conducted at the Allen Institute, where they recorded tens of thousands of neurons from six different cortical regions across multiple experimental conditions.\n\nIn this post, I'll take the recordings from a single animal that was presented with bright flashes.\nI'll visualize the responses across cortical regions in peri-stimulus time histograms (PSTHs) using Pandas and Seaborn.\nWhy Pandas and Seaborn?\nWhile these libraries are not geared towards electrophysiological data, they offer established powerful tools for analyzing large amounts of data.\nA good understanding of Pandas and Seaborn will also be useful in a variety of scenarios since these libraries are widely used in academia and industry.\n\nTo follow along with my examples, install the required packages and download the data as described in the next section.\n\n## Prerequisites\n\nFirst we have to install the required modules using `pip`:\n```\npip install numpy matplotlib seaborn pandas pyarrow\n```\nThen, we can import the installed modules and download the data.\nWe need two data frames --- one containing the timing of the presented stimuli and another one containing the recorded spikes.\nConveniently, all `read_` functions in Pandas accept URLs and can gracefully handle the downloading for us.\n\n::: {#5f2f29c3 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\ndf_stimuli = pd.read_parquet(\"https://uni-bonn.sciebo.de/s/G64EkHoQkeZeoLm/download\")\ndf_spikes = pd.read_parquet(\"https://uni-bonn.sciebo.de/s/mLMkb2TwbNx3Yg6/download\")\n```\n:::\n\n\n## Referencing Spike Times to Stimulus Presentations\n\nFirst, let's take a look at the data.\nWe have two data frames:\n`df_stimuli` contains the start and stop time for every stimulus [^2] and `df_spikes` contains the unit ID, brain area and time for every recorded spike.\n\n::: {#tbl-stim .cell tbl-cap='Stimuli' execution_count=2}\n``` {.python .cell-code}\ndf_stimuli.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_time</th>\n      <th>stop_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1276.297013</td>\n      <td>1276.547221</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1280.300363</td>\n      <td>1280.550569</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1286.305383</td>\n      <td>1286.555591</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1290.308743</td>\n      <td>1290.558946</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1294.312073</td>\n      <td>1294.562279</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#tbl-spikes .cell tbl-cap='Recorded spikes' execution_count=3}\n``` {.python .cell-code}\ndf_spikes.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit_id</th>\n      <th>brain_area</th>\n      <th>spike_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>951031334</td>\n      <td>LM</td>\n      <td>1276.297339</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>951031154</td>\n      <td>LM</td>\n      <td>1276.298206</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>951031243</td>\n      <td>LM</td>\n      <td>1276.298739</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>951021543</td>\n      <td>PM</td>\n      <td>1276.299007</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>951031253</td>\n      <td>LM</td>\n      <td>1276.301272</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nTo be able to relate the spiking to the presented stimuli, we have to combine the information from @tbl-stim and @tbl-spikes.\nTo do this, we first create a new column in the stimulus dataframe called `\"analysis_window_start\"`[^3] which is simply the stimulus onset minus 0.5 seconds. Then, we use `pd.merge_asof()` to match every spike with the closest analysis window. In the merged data frame `df`, we subtract the stimulus start time from the spike time which gives us the spike time relative to the stimulus.\nFinally, we remove all relative spike time values greater than 1 and remove the columns we don't need. The final dataframe contains all spikes happening between 0.5 seconds before and 1.0 seconds after stimulus onset.\n\n::: {#tbl-merged .cell tbl-cap='Spike times relative to stimulus onset' execution_count=4}\n``` {.python .cell-code}\ndf_stimuli[\"analysis_window_start\"] = df_stimuli.start_time - 0.5\ndf = pd.merge_asof(\n    df_spikes, df_stimuli, left_on=\"spike_time\", right_on=\"analysis_window_start\"\n)\ndf.spike_time -= df.start_time\ndf = df[df.spike_time <= 1.0]\ndf = df[[\"spike_time\", \"brain_area\", \"unit_id\"]]\ndf.sample(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spike_time</th>\n      <th>brain_area</th>\n      <th>unit_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>206450</th>\n      <td>0.655933</td>\n      <td>AM</td>\n      <td>951016725</td>\n    </tr>\n    <tr>\n      <th>365740</th>\n      <td>0.149013</td>\n      <td>V1</td>\n      <td>951026880</td>\n    </tr>\n    <tr>\n      <th>209042</th>\n      <td>0.549364</td>\n      <td>PM</td>\n      <td>951021642</td>\n    </tr>\n    <tr>\n      <th>147948</th>\n      <td>-0.065670</td>\n      <td>V1</td>\n      <td>951028431</td>\n    </tr>\n    <tr>\n      <th>284544</th>\n      <td>0.616993</td>\n      <td>LM</td>\n      <td>951030689</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Creating a Peri-Stimulus Time Histogram\n\nNow we can quantify how the spiking changes in response to the stimulus.\nTo do this, we create an array of 10 millisecond wide bins between -0.5 and 1.0 seconds, group the data by unit ID and brain area and count the spike time values that fall into each bin. Finally, we reset the index of the returned series, take the middle of each bin and rename the columns. The resulting dataframe contains the spike count for every unit in every bin.\n\n::: {#tbl-psth .cell tbl-cap='Peri-stimulus time histogram' execution_count=5}\n``` {.python .cell-code}\nbins = np.arange(-0.5, 1, 0.01)\npsth = (\n    df.groupby([\"unit_id\", \"brain_area\"])\n    .spike_time.value_counts(bins=bins)\n    .reset_index()\n)\npsth.spike_time = psth.spike_time.array.mid\npsth.columns = [\"unit_id\", \"brain_area\", \"bin_time\", \"spike_count\"]\npsth.sample(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit_id</th>\n      <th>brain_area</th>\n      <th>bin_time</th>\n      <th>spike_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>49372</th>\n      <td>951035490</td>\n      <td>AL</td>\n      <td>-0.085</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>40351</th>\n      <td>951031503</td>\n      <td>LM</td>\n      <td>0.815</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17261</th>\n      <td>951021665</td>\n      <td>PM</td>\n      <td>0.495</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10863</th>\n      <td>951018167</td>\n      <td>AM</td>\n      <td>0.685</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>885</th>\n      <td>951015763</td>\n      <td>AM</td>\n      <td>0.665</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nTo visualize the PSTH, we'll use seaborn's `relplot()` function to plot the spike counts against the bin times. We can also add reference lines at 0 and 0.25 seconds that mark the stimulus onset and offset. There is a clear pattern --- spiking increases after the onset, falls back to baseline, increases again after the offset, drops below the baseline and then rebounds.\n\n::: {#cell-fig-average_psth .cell execution_count=6}\n``` {.python .cell-code}\ng = sns.relplot(data=psth, x=\"bin_time\", y=\"spike_count\", kind=\"line\")\ng.refline(x=0, color=\"black\", linestyle=\"--\", alpha=0.5)\ng.refline(x=0.25, color=\"black\", linestyle=\"--\", alpha=0.5)\n```\n\n::: {.cell-output .cell-output-display}\n![Average time-binned spike count between 500 ms before and 1000 ms after stimulus onset. The shaded interval shows the 95% confidence-interval and the vertical dashed lines show the stimulus onset (0 s) and offset (0.25 s).](index_files/figure-ipynb/fig-average_psth-output-1.png){#fig-average_psth}\n:::\n:::\n\n\nWe can also add a `hue` to encode the brain area and zoom in on the x-axis in order to make out differences in the spiking profile between brain areas (we'll set `errorbar=None` because the overlapping confidence intervals will make the plot hard to read).\n\n::: {#cell-fig-area_psth .cell execution_count=7}\n``` {.python .cell-code}\ng = sns.relplot(data=psth, x=\"bin_time\", y=\"spike_count\", kind=\"line\" , hue=\"brain_area\", errorbar=None)\ng.set(xlim=(-0.1, 0.5))\n```\n\n::: {.cell-output .cell-output-display}\n![Average time-binned spike count between 500 ms before and 1000 ms after stimulus onset for each visual cortex area.](index_files/figure-ipynb/fig-area_psth-output-1.png){#fig-area_psth}\n:::\n:::\n\n\nWe can see that spiking in the primary visual cortex V1 peaks first which is expected since it represents the lowest level in the visual processing hierarchy. However, there are large differences in the average firing rate between areas which makes this plot hard to read. To overcome this limitation we have to apply baseline correction.\n\n## Applying a Baseline Correction\n\nTo compute the baselines, we select all spikes that happen before 0 seconds (i.e. the stimulus onset), group the data by unit ID and calculate the mean spike count to obtain an estimate of each unit's average firing rate in absence of the stimulus. Then, we merge the baseline estimates with the PSTH and create a new column called `\"spike_count_change\"` by subtracting the baseline from the spike count.\n\n::: {#tbl-baseline .cell tbl-cap='Baseline-corrected spike counts' execution_count=8}\n``` {.python .cell-code}\nbaseline = psth[psth.bin_time < 0].groupby([\"unit_id\"]).spike_count.mean()\nbaseline.name = \"baseline\"\npsth = psth.merge(baseline, on=\"unit_id\")\npsth[\"spike_count_change\"] = psth.spike_count - psth.baseline\npsth.sample(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit_id</th>\n      <th>brain_area</th>\n      <th>bin_time</th>\n      <th>spike_count</th>\n      <th>baseline</th>\n      <th>spike_count_change</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32898</th>\n      <td>951027930</td>\n      <td>V1</td>\n      <td>0.275</td>\n      <td>4</td>\n      <td>9.28</td>\n      <td>-5.28</td>\n    </tr>\n    <tr>\n      <th>52894</th>\n      <td>951035763</td>\n      <td>AL</td>\n      <td>0.985</td>\n      <td>0</td>\n      <td>0.32</td>\n      <td>-0.32</td>\n    </tr>\n    <tr>\n      <th>40214</th>\n      <td>951031494</td>\n      <td>LM</td>\n      <td>0.435</td>\n      <td>1</td>\n      <td>2.90</td>\n      <td>-1.90</td>\n    </tr>\n    <tr>\n      <th>47270</th>\n      <td>951035304</td>\n      <td>AL</td>\n      <td>-0.225</td>\n      <td>0</td>\n      <td>0.22</td>\n      <td>-0.22</td>\n    </tr>\n    <tr>\n      <th>48555</th>\n      <td>951035414</td>\n      <td>AL</td>\n      <td>0.645</td>\n      <td>1</td>\n      <td>4.38</td>\n      <td>-3.38</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNow we can recreate our area-specific PSTH plot using the spike count change --- the result looks much clearer!  \n\n::: {#cell-fig-baseline_psth .cell execution_count=9}\n``` {.python .cell-code}\ng = sns.relplot(\n    data=psth,\n    x=\"bin_time\",\n    y=\"spike_count_change\",\n    kind=\"line\",\n    hue=\"brain_area\",\n    errorbar=None,\n)\ng.set(xlim=(-0.1, 0.5))\n```\n\n::: {.cell-output .cell-output-display}\n![Baseline-corrected changes in spike count between 100 ms before and 500 ms after stimulus onset across brain areas.](index_files/figure-ipynb/fig-baseline_psth-output-1.png){#fig-baseline_psth}\n:::\n:::\n\n\nHowever, there is still a problem: the number of units that respond to the stimulus varies across brain areas as higher visual areas generally respond less to simple flashes which confounds our analysis. In order to interpret the absolute spike counts we need to identify the units that actually respond to the stimuli.\n\n## Identifying Responsive Units\n\nTo identify the responsive units, we first compute the relative change in spiking by dividing the baseline subtracted spikecount by the baseline. \nWe add a small regularization coefficient $\\epsilon$ to avoid that baseline values close to 0 inflate the estimate [^4]. \nThen, we can plot the relative change in spiking for every unit (this requires setting `estimator=None`).\nLet's add a horizontal line to mark the threshold for responsiveness --- in this example, we want to consider a unit responsive if its relative spike count increases 5 times with respect to the baseline.\nThis method of identifying responsive units is not statistically rigorous, but it is a quick and convenient way of filtering the data for visualization.\n\n::: {#cell-fig-relative_psth .cell execution_count=10}\n``` {.python .cell-code}\nepsilon = 0.5\nthreshold = 5\npsth[\"rel_spike_count_change\"] = (psth.spike_count - psth.baseline) / (\n    psth.baseline + epsilon\n)\ng = sns.relplot(\n    psth,\n    x=\"bin_time\",\n    y=\"rel_spike_count_change\",\n    units=\"unit_id\",\n    kind=\"line\",\n    estimator=None,\n)\ng.refline(y=threshold, color=\"black\", linestyle=\"--\", alpha=0.5)\n```\n\n::: {.cell-output .cell-output-display}\n![Each unit's change in the time-binned spike counts relative to the baseline. The horizontal line marks the threshold above which a unit is considered responsive.](index_files/figure-ipynb/fig-relative_psth-output-1.png){#fig-relative_psth}\n:::\n:::\n\n\nNow, we group the data by unit ID and check whether each unit's maximum value for the relative change in spike count is above the selected threshold.\nThen, we merge the result with the PSTH to get a new column with boolean  values that indicate whether any given unit is responsive.\nFinally, we can reproduce @fig-baseline_psth selecting only the units that are responsive according to our threshold criterion.\n\n::: {#cell-fig-responsive_psth .cell execution_count=11}\n``` {.python .cell-code}\nis_responsive = psth.groupby([\"unit_id\"]).rel_spike_count_change.max() > threshold\nis_responsive.name = \"is_responsive\"\npsth = psth.merge(is_responsive, on=\"unit_id\")\ng = sns.relplot(\n    data=psth[psth.is_responsive],\n    x=\"bin_time\",\n    y=\"spike_count_change\",\n    kind=\"line\",\n    hue=\"brain_area\",\n    errorbar=None,\n)\ng.set(xlim=(-0.1, 0.5))\n```\n\n::: {.cell-output .cell-output-display}\n![Baseline-corrected changes in spike count in units with an above-threshold response to the stimuli. Note that there are only 5 brain areas since no neuron from area RL exceeded the threshold.](index_files/figure-ipynb/fig-responsive_psth-output-1.png){#fig-responsive_psth}\n:::\n:::\n\n\nNow the differences in response latency between the areas are much clearer. We can also make out some interesting trends --- for example, units in V1 appear to respond mostly to the stimulus onset while units in LM respond more strongly to the offset.\n\n## Closing Remarks\n\nThe goal of this post was to show how you can use Pandas and Seaborn to create detailed and informative graphs from large datasets (i.e. tables with hundreds of thousands of rows) with relatively little code.\nThe methods for data aggregation, merging and visualization shown here will be applicable to any data that can be arranged in a tabular format.\nWhat this demo lacks is a statistical comparison of the spiking activity between brain areas.\nThis was outside of the scope of this post since I only used data from a single animal.\nIf you are interested in working with the full dataset you can check out my [GitHub repo](https://github.com/OleBialas/Ecephys-Recordings-from-Mouse-Visual-System) which contains the recordings from over 50 animals in the same data format used in this demo.\n\n\n[^1]: Siegle, J. H., Jia, X., Durand, S., Gale, S., Bennett, C., Graddis, N., ... & Koch, C. (2021). Survey of spiking in the mouse visual system reveals functional hierarchy. Nature, 592(7852), 86-92.\n[^2]: All stimuli are full-field flashes so there isn't any relevant information besides the stimuli's timing\n[^3]: We could skip creating the `\"analysis_window_start\"` column and merge the data using the stimulus onsets. However, then we would lose the spikes that occur right before the onset which we need to compute the baseline.\n[^4]: The exact value of $\\epsilon$ is not that relevant here, so feel free to try out different values. However, be aware that larger values of $\\epsilon$ will lead to smaller values of the relative change in spike count for all units, so you'll have to adapt the threshold as well.\n\n---\njupyter:\n  kernelspec:\n    display_name: Python 3 (ipykernel)\n    language: python\n    name: python3\n    path: /home/olebi/projects/new_website/.pixi/envs/default/share/jupyter/kernels/python3\n  language_info:\n    codemirror_mode:\n      name: ipython\n      version: 3\n    file_extension: .py\n    mimetype: text/x-python\n    name: python\n    nbconvert_exporter: python\n    pygments_lexer: ipython3\n    version: 3.13.5\n---\n",
    "supporting": [
      "index_files/figure-ipynb"
    ],
    "filters": []
  }
}